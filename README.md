# pad_ml_project

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

for uni  homeworks
–®–∞–±–ª–æ–Ω –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è ML‚Äë–¥–æ–º–∞—à–µ–∫ (DS‚Äëcookiecutter + S3 + MLflow + Docker)

–ü—Ä–æ–µ–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:
- –ª–æ–∫–∞–ª—å–Ω—ã–π S3 (MinIO)
- MLflow —Ç—Ä–µ–∫–∏–Ω–≥ + PostgreSQL
- –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≥—Ä—É–∑–∫–∏/–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- –∑–∞–ø—É—Å–∫ ML‚Äë—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- –ø–æ–¥–¥–µ—Ä–∂–∫—É –ª–∏–Ω—Ç–∏–Ω–≥–∞ –∏ mypy
- –∑–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ

---

## 1Ô∏è‚É£ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:

```bash
git clone https://github.com/fuckseer/study_project_ml.git
cd study_project_ml

uv venv --python 3.12
uv pip install -r requirements.txt
```

–ò–õ–ò –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π:

```bash
bash setup_project.sh
```

---

## 2Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã (MinIO, PostgreSQL, MLflow, Training)

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `docker-compose`:

```bash
docker compose up -d --build
```

–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤:

```bash
docker compose ps
```

–î–æ–ª–∂–Ω—ã –ø–æ–¥–Ω—è—Ç—å—Å—è 4 —Å–µ—Ä–≤–∏—Å–∞:

- `minio` ‚Äî –ª–æ–∫–∞–ª—å–Ω—ã–π S3  
- `db` ‚Äî PostgreSQL –¥–ª—è MLflow  
- `mlflow` ‚Äî MLflow Tracking Server  
- `training` ‚Äî –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è  

---

## 3Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MinIO (–ª–æ–∫–∞–ª—å–Ω—ã–π S3)

–û—Ç–∫—Ä–æ–π:

http://localhost:9001  
–ª–æ–≥–∏–Ω: **admin**  
–ø–∞—Ä–æ–ª—å: **admin123**

–°–æ–∑–¥–∞–π 2 bucket‚Äë–∞:

```
study-project-data
mlflow-artifacts
```

–ü–æ–º–µ—Å—Ç–∏ –≤ `study-project-data` —Å—ã—Ä–æ–π –¥–∞—Ç–∞—Å–µ—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä:

```
titanic.csv
```

---

## 4Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è

–°–æ–∑–¥–∞–π `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```
AWS_ACCESS_KEY_ID=admin
AWS_SECRET_ACCESS_KEY=admin123
S3_ENDPOINT_URL=http://minio:9000

RAW_BUCKET=study-project-data
PROCESSED_BUCKET=study-project-data

MLFLOW_TRACKING_URI=http://mlflow:5000
```

---

## 5Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö

–°–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç:

1. –∑–∞–≥—Ä—É–∑–∫—É —Å—ã—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ ‚Üí S3  
2. —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤ `data/raw/`  
3. –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ `data/processed/`  
4. –∑–∞–≥—Ä—É–∑–∫—É –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞—Ç–Ω–æ –≤ S3  

–ó–∞–ø—É—Å–∫:

```bash
docker compose exec training python -m study_project_ml.pad_project_ml.pipeline_s3
```

–û–∂–∏–¥–∞–µ–º—ã–π –ª–æ–≥:

```
‚¨áÔ∏è  Download s3://study-project-data/titanic.csv
üîß Processing dataset...
‚¨ÜÔ∏è  Upload ... ‚Üí s3://study-project-data/titanic_processed.csv
üéØ Pipeline finished successfully
```

---

## 6Ô∏è‚É£ –ó–∞–ø—É—Å–∫ ML‚Äë—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (MLflow + S3)

–°–µ—Ç–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–ø–∏—Å–∞–Ω–∞ –≤:

```
config/experiments.yml
```

–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:

```bash
bash run_experiments.sh
```

–ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç:

- —Å–∫–∞—á–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ S3  
- –æ–±—É—á–∞–µ—Ç LogisticRegression  
- –ª–æ–≥–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã + –º–µ—Ç—Ä–∏–∫–∏ –≤ MLflow  
- —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç model.pkl –∏ metrics.json  
  - –≤ MLflow –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã  
  - –≤ MinIO –ø–æ –ø—É—Ç–∏:

```
s3://study-project-data/<experiment_name>/model_*.pkl
s3://study-project-data/<experiment_name>/metrics_*.json
```

---

## 7Ô∏è‚É£ –ü—Ä–æ—Å–º–æ—Ç—Ä —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤ MLflow

–û—Ç–∫—Ä–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:

```
http://localhost:5001
```

–ó–¥–µ—Å—å –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è:
- —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã  
- –ø–∞—Ä–∞–º–µ—Ç—Ä—ã  
- –º–µ—Ç—Ä–∏–∫–∏ (accuracy, roc_auc)  
- –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã (–º–æ–¥–µ–ª–∏, –º–µ—Ç—Ä–∏–∫–∏)  

---

## 8Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è –∫–æ–¥–∞

–ü–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–∞–º–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç `pre-commit`, –Ω–æ –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Ä—É—á–Ω—É—é:

```bash
uv run flake8 study_project_ml
uv run mypy study_project_ml
```

---

## 9Ô∏è‚É£ –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã Docker

–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É:

```bash
docker compose down
```

–û—á–∏—Å—Ç–∏—Ç—å —Å —Ç–æ–º–∞–º–∏:

```bash
docker compose down -v
```

–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –ø—Ä–æ–µ–∫—Ç:

```bash
docker compose build training
```

–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ª–æ–≥–∏ MLflow:

```bash
docker compose logs -f mlflow
```

–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ MinIO —á–µ—Ä–µ–∑ CLI:

```bash
docker compose exec mlflow aws --endpoint-url http://minio:9000 s3 ls
```


## Project Organization

```
‚îú‚îÄ‚îÄ LICENSE            <- Open-source license if one is chosen
‚îú‚îÄ‚îÄ Makefile           <- Makefile with convenience commands like `make data` or `make train`
‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ external       <- Data from third party sources.
‚îÇ   ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.
‚îÇ   ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.
‚îÇ   ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.
‚îÇ
‚îú‚îÄ‚îÄ docs               <- A default mkdocs project; see www.mkdocs.org for details
‚îÇ
‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries
‚îÇ
‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.
‚îÇ                         `1.0-jqp-initial-data-exploration`.
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml     <- Project configuration file with package metadata for 
‚îÇ                         pad_ml_project and configuration for tools like black
‚îÇ
‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
‚îÇ
‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
‚îÇ   ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
‚îÇ                         generated with `pip freeze > requirements.txt`
‚îÇ
‚îú‚îÄ‚îÄ setup.cfg          <- Configuration file for flake8
‚îÇ
‚îî‚îÄ‚îÄ pad_ml_project   <- Source code for use in this project.
    ‚îÇ
    ‚îú‚îÄ‚îÄ __init__.py             <- Makes pad_ml_project a Python module
    ‚îÇ
    ‚îú‚îÄ‚îÄ config.py               <- Store useful variables and configuration
    ‚îÇ
    ‚îú‚îÄ‚îÄ dataset.py              <- Scripts to download or generate data
    ‚îÇ
    ‚îú‚îÄ‚îÄ features.py             <- Code to create features for modeling
    ‚îÇ
    ‚îú‚îÄ‚îÄ modeling                
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py 
    ‚îÇ   ‚îú‚îÄ‚îÄ predict.py          <- Code to run model inference with trained models          
    ‚îÇ   ‚îî‚îÄ‚îÄ train.py            <- Code to train models
    ‚îÇ
    ‚îî‚îÄ‚îÄ plots.py                <- Code to create visualizations
```

--------

